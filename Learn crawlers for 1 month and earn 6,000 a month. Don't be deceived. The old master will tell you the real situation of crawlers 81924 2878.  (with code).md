This is a true story I saw a few days ago, and it's why I'm writing this article. 

A few days ago, a fan reported to me that someone from a certain institution told him that he could take orders for learning crawlers in one month, and asked this young man to sign up for the crawler course of that institution, and he could earn back more than 6,000 tuition fees in one month. Maybe because I communicate with fans a lot, the young man came to me and asked me if this was true or not, and I couldn't help but be shocked... 

Can you earn more than 6,000 yuan by learning crawlers for 1 month? There are countless people who can crawl now, and beginners can earn 6,000 yuan a month by learning crawlers in 1 month? 

![avatar]( c6520a52c08b49c78387917871279df3.jpg) 

Adhering to an objective attitude, even if I didn't believe it, I didn't come to a conclusion. Instead, I took a look at their course system, and the result was not what I expected. Most of the courses were about introductory knowledge of Python (functions, etc.), requests, and XPath. Isn't this all knowledge of some beginner crawlers? Can you earn 6000 a month? Why don't you teach young people to go to the street to grab money? 

I have also been working on making extra money for many years, and crawlers are naturally no problem. So today I will talk about 5 in-depth crawler problems to let you know the real situation of crawlers: 

>  Can the current crawler really earn 6000 yuan a month? 

>  2. Beginner reptiles can only take some small orders. What is the level of beginner reptiles? 

>  3. Intermediate crawlers are professional crawler engineers. What are the requirements? 

>  4. Advanced reptiles can be said to be the god of reptiles. What skills do you need to master? 

>  5. What do you need to learn at a higher level of crawlers? What does a peak crawler look like? 

###  Can a reptile earn 6,000 extra dollars a month? 

The answer is definitely yes, but it depends on your level of crawling skills. 

If you are just a beginner crawler, you can only rely on luck to receive orders. Some of the crawler works you can get your hands on may not be able to enter the eyes of the top gifter. Sometimes it is more difficult to pick up a technical one, and the whole effect will take several days. Most beginner crawlers will not receive orders for more than 200 yuan, and most of them are orders for tens of dollars. How many orders do you need to receive to earn 6,000 per month? Even if your average price for an order is 100 yuan, then you still need 60 orders! 

Anyone who has worked part-time knows that 60 private jobs a month is almost impossible, unless you have a special channel. 

Furthermore, aside from the beginner crawlers and even product managers, there are now so many third-party websites that offer powerful crawler functions, which can be solved by people who do not crawl for a small amount of money. For example, a certain claw fish or a certain type of collector, whether it is time or cost, it is better than paying for a novice crawler. 

![avatar]( 36c8e2f7385845d89201b716cedcb646.jpg) 

 Novices can earn 6,000 yuan a month by learning crawlers in one month. I can guarantee that this is just to encourage you to sign up for classes. This method is not uncommon in the Internet education industry, which is of mixed quality. I will directly give my conclusion: It is not worth the money. After learning, you can't earn 6,000 yuan by crawling in January. This level is not enough to make you a year.  

But if your skills reach the level of intermediate crawler or higher, it is relying on strength and luck to make money. From a technical point of view, there is no problem with taking bigger orders, and the price of an order also ranges from 300 to thousands. If the average price is 600 yuan for an order, it is no problem to make four or five orders a month to earn thousands of dollars. If you fight a little or have better skills, you may earn more, provided that you have this technology. 

It's possible to make $6,000, and I've made orders for thousands of dollars before. 

![avatar]( 1b13440bbe784f62968499eb33ce0d74.png) 

As for where to take orders is already a commonplace, I won't say much here, go to Baidu yourself, Baidu has everything, let's continue the following topic, let's see what the beginner, intermediate, advanced and peak levels of crawlers look like! 

>  I have a lot of technical dry goods in my private stash, and fans can use them for free (click here). 

###  Second, primary reptiles 

Based on what I've known about reptiles over the years, the level of a beginner reptile looks something like this: 

![avatar]( 722e2b1572734cd9bc22d25da4d54e12.png) 

  (Recently, compared with people who stole pictures and text, the pictures have been watermarked in order to prevent unscrupulous CV Dafa. If you need source files, you can chat with me privately.) 

What can this level do? It's just crawling some basic websites, involving a bit of reverse crawling on GG. 

For example, if we go to crawl an article on a website that does not have an anti-crawl mechanism, it is enough to use libraries such as requests. We can use XPath, BeautifulSoup, PyQuery, or regular expressions to analyze the source code of the webpage, and then add a text to write and save it. 

The difficulty is not big, it is nothing more than a few method calls and circular storage. If the storage is slightly expanded, you can connect to MySQL, MongoDB, Elasticsearch, Kafka, etc. to save data and achieve persistent storage. It will be more convenient to query or operate in the future. 

This was the level of a beginner crawler. It could crawl, but it was still a long way from being "able to crawl". It was conceivable that it would be more difficult to receive orders. 

![avatar]( d2e7afedc1fd4458a53c26e9b7280c09.png) 

 Then let's look back at the previous young man's matter. Can the above things be learned in a month for beginners? I think the difficulty is not small, and I will say nothing else. The entry to Python contains a lot of things.   

4 hours a day to learn. Without a basic foundation, it may take you 2 weeks to learn Python. In the remaining two weeks, can you learn and master the remaining knowledge of beginner crawlers? 

Technology is very taboo on the road of quick success. I know you can read and understand a book from start to night in just a few days, but can you use it after reading it? You read it, but you can't remember what you read. You need to practice it repeatedly. Similarly, you can learn it in a month without any problem, but whether you can stand firm or not is still a problem. 

What's more, some institutions' courses are all selective. 

###  Intermediate reptiles 

The level of an intermediate crawler can be regarded as the basic level of a professional crawler. In addition to the knowledge points of beginner crawlers, you should also master the following knowledge points: 

![avatar]( c24f969deef64b86a6011755a53bf652.png) 

When your requests are not useful (the ones that crawl down are different from those displayed on the webpage), you should think that the data source may be Ajax, and you need to understand JavaScript when analyzing the website; if you want to bypass the process of analyzing Ajax and some JavaScript logic to Crawling the data, we have to use Puppeteer, Pyppeteer, Selenium, Splash, etc. to simulate the browser to crawl. 

In addition to the crawling method, there is also the crawling speed. At this time, you need to have knowledge of multiple processes, multiple threads, and coroutines. 

If you can only crawl web pages, then you are not at the level of an intermediate crawler. You have to be able to crawl apps, which also account for half of the country. 

At this time, you will have to capture Charles and Fiddler packages, and then use them to simulate them. If the interface is encrypted, you can use mitmproxy to directly monitor the interface data or use Hook, such as Xposed. 

Another important thing when crawling the APP is to automatically crawl. If you manually poke to achieve crawling, it is useless to pay more money, this is not a personal job... The better solution is adb tools and Appium, do you think you should learn? 

![avatar]( 9b652ada26b54859903b70bb239a9496.jpg) 

>  I have a lot of technical dry goods in my private stash, and fans can use them for free (click here). 

###  IV. Advanced reptiles 

Advanced crawlers have great advantages whether in the workplace or part-time. Advanced crawlers should master the following skills: 

![avatar]( dd365a1be07a4e4d841d6fdd61ebd388.png) 

Anyone who has come into contact with large-scale crawlers will understand that although multi-threading, multi-process, and coroutines can speed up crawling, they are still a stand-alone crawler, which is much inferior to more advanced distributed crawlers. Distributed crawlers can be regarded as enterprise-level crawlers. 

The center of gravity of distributed crawlers lies in resource sharing, so what we need to master is RabbitMQ, Celery, and Kafka, which are used to implement distribution with these basic queues or components; followed by our famous Scrapy crawler framework, which is also the most widely used crawler framework at present. It is essential to understand and master Scrapy's Redis, Redis-BloomFilter, and Cluster. 

After mastering these things, your crawler can achieve enterprise-level high-efficiency crawlers. 

![avatar]( c77bc10633f140ac825ea2103171a274.jpg) 

Another focus that advanced crawler levels should consider is anti-crawling. 

The common operation of the anti-crawl mechanism is the verification code, what slider verification ah, physical check ah, addition and subtraction ah, etc., the moves are endless, this time you have to know how to deal with these common verification code. 

There is also the common IP detection in anti-crawling, which may block your number, so coping methods are also necessary. Whether you use a free proxy or a paid proxy to change the proxy IP, it is possible. 

As well as the shunt technology to deal with anti-climbing to avoid account blocking, shunt technology has to build a pool, Cookies pool, Token pool, Sign pool, you can, with the pool, your probability of being blocked will be reduced, you don't want to climb an official account result WX was blocked, right? 

![avatar]( 2e06f9aa133c4456bb3aa44ec42891f0.jpg) 

###  Fifth, higher-level reptiles (the pinnacle of reptiles) 

For higher-level crawlers, the following 4 points are essential: 

![avatar]( 489c71221b2a401b963449d7b52a5ae9.png) 

Why learn JS reverse crawling? In the fight between reverse crawling and reverse crawling, it is also possible to use Selenium and other methods to crawl, but the efficiency is still low. After all, it simulates the entire process of web page rendering, and the real data may only be hidden in a small interface. Therefore, JS reverse crawling is a higher-level crawling technology, especially in large-scale website data crawling, such as a lot and a treasure. If you can use JS reverse crawling, it is undoubtedly one of the proof of technical excellence, but JS reverse is not something that everyone can refine. It does burn hair. 

Not to mention the reverse of the APP, the web page can be reversed, and the APP can also be reversed, so you deserve the word "awesome". 

What is an intelligent crawler? For example, under normal circumstances, a crawler that crawls a novel website needs to write different extraction rules according to different websites in order to extract the desired content. And if you use intelligent analysis, no matter which website it is, you only need to pass the URL of the webpage to it, and you can intelligently identify the title, content, update time and other information through the algorithm, without repeatedly writing extraction rules. 

Intelligent crawler, in short, is the combination of crawler and machine learning technology, making crawler more intelligent, otherwise, to crawl 10,000 website, do we have to write 10,000 crawler script? 

![avatar]( 26d1a748b6fd41e6b1794a31a36556eb.jpg) 

When did crawlers become involved in operations and maintenance? They have always had an inseparable relationship, but your crawler needs or level have not been met, so they will not be considered. 

The relationship between crawlers and operation and maintenance is mainly reflected in the deployment and distribution, data storage and monitoring. 

For example, how to quickly deploy a crawler to 100 hosts? For example, how to monitor the memory and CPU status of some crawlers? For example, how can crawlers set up alarm mechanisms to ensure the safety of crawler projects? 

Kubernetes, Prometheus, and Grafana are the most used technologies in the operation and maintenance of crawlers, and I often use them to escort when doing larger crawler projects. 

What is a peak? There may never be a peak... As long as I don't have the hairstyle of a powerhouse (completely bald) for a day, I dare not say that I have seen a peak... 

I vaguely feel that the crawler has achieved the extreme, capable of doing both full stack and data analytics. It is better to say that it is still a master of algorithms. Maybe it can also make achievements in artificial intelligence. Is this the peak of crawlers? 

Today's sharing is here, may you and I both become men at the top of the pyramid! 

>  I have a lot of technical dry goods in my private stash, and fans can use them for free (click here). 

![avatar]( 26fc382fa23343bc914d46f062a2bacd.png) 

